{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docker command\n",
    "docker run -it -p 127.0.0.1:8887:8888 -v ~/workspace/sequenceSLAM/src/ipy:/workspace -v ~/dataset/:/workspace/dataset/ souravgarg/opencv-python-udacity-caffe:cpu\n",
    "\n",
    "nvidia-docker run -it -p 192.168.5.78:8887:8888 -v ~/workspace/dataset/:/workspace/dataset/ -v ~/workspace/:/workspace/ caffe-gpu-jupyter-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import StringIO\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up input/output for annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folderPath = '../../dataset/transient_attributes/annotations/'\n",
    "if os.path.exists(folderPath) is False:\n",
    "    print(\"Folder path doesn't exist.\")\n",
    "    \n",
    "attributes = np.loadtxt(folderPath+'attributes.txt',dtype='str')\n",
    "\n",
    "annotationsFileName = folderPath+'annotations.tsv'\n",
    "\n",
    "# Col 1 is file name, col 2-41 are attributes, splitting each attribute column 'score,conf'\n",
    "# Hence, an att index i has its score at 2i+1 and conf at 2i+1\n",
    "s = open(annotationsFileName).read().replace(',','\\t')\n",
    "annotations = np.loadtxt(StringIO.StringIO(s),dtype='str')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up input/output for images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folderPath2 = '../../dataset/transient_attributes/imageAlignedLD/'\n",
    "if os.path.exists(folderPath2) is False:\n",
    "    print(\"Folder path doesn't exist.\")\n",
    "\n",
    "folderPath3 = '../../dataset/transient_attributes/outData/'\n",
    "if os.path.exists(folderPath3+'train/') is False:\n",
    "    os.mkdir(folderPath3+'train/')\n",
    "    os.mkdir(folderPath3+'val/')\n",
    "    os.mkdir(folderPath3+'test/')\n",
    "\n",
    "outImgNamesFile = 'concatImgsList.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect unique webcams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allCams = annotations[:,0]\n",
    "allCams = [os.path.split(elem)[0] for elem in allCams.tolist()]\n",
    "uniCams, retIdx = np.unique(allCams,return_index=True)\n",
    "\n",
    "# check if retIdx is ordered\n",
    "if (np.sum(np.subtract(np.sort(retIdx),retIdx))) == 0:\n",
    "    print(\"cam folders are in order, retIdx can be used as splitting range for cam folder images\")\n",
    "else:\n",
    "    print(\"WARNING: cam folders not in order\")\n",
    "\n",
    "camFolderAnnot = np.split(annotations,retIdx[1:])\n",
    "print(len(camFolderAnnot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desiredAttributes = [1,2] # attributes in attributes.txt, 1 is for daylight, 2 for night etc...\n",
    "minConf = 5 # min confidence votes to consider the image\n",
    "minScore = 0.8 # min score (0 to 1) to consider the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect the image names for desired attribute based on confidence and score values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getIndicesForDesiredAttribute(inputArr,desiredAtt,minScore,minConf):\n",
    "    index = 2*desiredAtt+1\n",
    "    # select the columns that fulfil the minScore and minConf conditions\n",
    "    val = np.greater_equal( inputArr[:,index:index+2].astype(float), \\\n",
    "               np.tile(np.array([[minScore,minConf]]),(inputArr.shape[0],1)).astype(float) \\\n",
    "              )\n",
    "    # ANDing the score and conf comparison\n",
    "    selIndices = val[:,0] * val[:,1]\n",
    "#     print(inputArr[selIndices,0])\n",
    "#     return selIndices\n",
    "    return inputArr[selIndices,0] # return the image names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop over all desired attributes\n",
    "desiredImgs = []\n",
    "numImgs = []\n",
    "for att in desiredAttributes:\n",
    "    print(\"Processing desired attribte \",att)\n",
    "    # collect the image names for each of the cam folders, as list of ndarrays\n",
    "    imgsList =  [getIndicesForDesiredAttribute(camFolderAnnot[i],att,minScore,minConf) \\\n",
    "                   for i in range(len(camFolderAnnot))] \n",
    "    desiredImgs.append(imgsList)\n",
    "    num = np.array([arr.shape[0] for arr in imgsList])\n",
    "    print(\"Number of images for each cam folder\",num)\n",
    "    numImgs.append(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create pairs of image names for selected attribute pair "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgPairIndices = []\n",
    "numPairs = 0\n",
    "for index in range(numImgs[0].shape[0]):\n",
    "    \n",
    "    # Lesser and greater indices are required to choose with or without replacement respectively\n",
    "    greaterIdx = 0\n",
    "    lesserIdx = 1\n",
    "    \n",
    "    # If any of cam folders have one of the attribute images count equal to zero\n",
    "    if numImgs[0][index] == 0 or numImgs[1][index] == 0:\n",
    "        imgPairIndices.append([])\n",
    "        continue\n",
    "    \n",
    "    # Set the indices\n",
    "    if numImgs[0][index] < numImgs[1][index]:\n",
    "        greaterIdx = 1\n",
    "        lesserIdx = 0\n",
    "        \n",
    "    # Get the random indices from both the attributes\n",
    "    ind1 = np.random.choice(desiredImgs[greaterIdx][index],replace=False,size=numImgs[greaterIdx][index])\n",
    "    ind2 = np.random.choice(desiredImgs[lesserIdx][index],replace=True,size=numImgs[greaterIdx][index])\n",
    "    \n",
    "    # Zip the pair values\n",
    "    if greaterIdx == 0:\n",
    "        imgPairIndices.append(zip(ind1,ind2))\n",
    "    else:\n",
    "        imgPairIndices.append(zip(ind2,ind1))\n",
    "    \n",
    "    numPairs += ind1.shape[0]\n",
    "    \n",
    "print(\"Total number of image pairs generated - \", numPairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "concatImgNames = []\n",
    "trainNum = 0.65*numPairs\n",
    "valNum = 0.15*numPairs\n",
    "testNum = numPairs - trainNum - valNum\n",
    "\n",
    "for idx,arr in enumerate(imgPairIndices):\n",
    "    print(\"Processing cam folder\",idx)\n",
    "    for pair in arr:\n",
    "\n",
    "        img1 = cv2.imread(folderPath2+str(pair[0]))\n",
    "        img2 = cv2.imread(folderPath2+str(pair[1]))\n",
    "        \n",
    "        img1 = cv2.resize(img1,(256,256))\n",
    "        img2 = cv2.resize(img2,(256,256))\n",
    "        \n",
    "        imgPair = np.hstack([img1,img2])#cv2.hconcat(img1,img2)\n",
    "        \n",
    "        concatImgNames.append(pair)       \n",
    "        \n",
    "        writePath = folderPath3\n",
    "        if counter < trainNum:\n",
    "            writePath += 'train/'\n",
    "        elif counter < (trainNum+valNum):\n",
    "            writePath += 'val/'\n",
    "        else:\n",
    "            writePath += 'test/'\n",
    "            \n",
    "        cv2.imwrite(writePath+str(counter)+'.jpg',imgPair)\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "#         plt.imshow(img1)\n",
    "#         plt.show()\n",
    "\n",
    "np.savetxt(folderPath3+outImgNamesFile,concatImgNames,fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Create another test dataset with some random images  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "while True:\n",
    "    counter += 1\n",
    "    img = cv2.imread(folderPath3+'test2/'+str(counter)+'.png')\n",
    "    \n",
    "    if img == None:\n",
    "        break\n",
    "    \n",
    "    img = cv2.resize(img,(256,256))\n",
    "    img = np.hstack([img,img])\n",
    "    cv2.imwrite(folderPath3+'test2/'+str(counter)+'_.png',img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data from two videos given corresponding frame indices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folderPath = \"../../dataset/slamData/surfers-paradise/\"\n",
    "vid1File = 'day.avi'\n",
    "vid2File = 'night.avi'\n",
    "\n",
    "originalGTindices1File = 'gt-surfers-paradise-day.txt'\n",
    "originalGTindices2File = 'gt-surfers-paradise-night.txt'\n",
    "\n",
    "interpGTFile = 'gt-surfers-paradise.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add the matching pairs from the originally manually selected ones\n",
    "originalGTindices1 = np.loadtxt(folderPath+originalGTindices1File,dtype=int)\n",
    "originalGTindices2 = np.loadtxt(folderPath+originalGTindices2File,dtype=int)\n",
    "\n",
    "indicesPair = np.vstack([originalGTindices1[:,0],originalGTindices2[:,0]]).transpose()\n",
    "print(indicesPair.shape)\n",
    "\n",
    "\n",
    "# Add some random pairs from the interpolated ground truth\n",
    "interGT = np.loadtxt(folderPath+interpGTFile,dtype=int)\n",
    "numPairs = 100\n",
    "randomGT = interGT[np.random.randint(0,interGT.shape[0],numPairs)]\n",
    "indicesPairRandom = np.vstack([randomGT[:,0],randomGT[:,1]]).transpose()\n",
    "print(indicesPairRandom.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getImagesFromVid(video,indices,imgOutPath):\n",
    "    indices = np.unique(indices)\n",
    "    print(indices.shape)\n",
    "    imgCounter = 0\n",
    "    indexIter = 0\n",
    "    for i in range(indices[-1]+1):\n",
    "        ret, img = video.read()\n",
    "        if ret is False:\n",
    "            print(\"read %d images, no more images...\"%imgCounter)\n",
    "            break\n",
    "        elif imgCounter == indices[indexIter]:\n",
    "            img = cv2.resize(img,(256,256))\n",
    "            cv2.imwrite(imgOutPath+str(imgCounter)+'.png',img)\n",
    "            imgCounter += 1\n",
    "            indexIter += 1\n",
    "        else:\n",
    "            imgCounter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgOutPath1 = folderPath + 'images/day/'\n",
    "cap1 = cv2.VideoCapture(folderPath+vid1File)\n",
    "indices1 = np.concatenate([originalGTindices1[:,0],randomGT[:,0]])\n",
    "getImagesFromVid(cap1,indices1,imgOutPath1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgOutPath2 = folderPath + 'images/night/'\n",
    "cap2 = cv2.VideoCapture(folderPath+vid2File)\n",
    "indices2 = np.concatenate([originalGTindices2[:,0],randomGT[:,1]])\n",
    "getImagesFromVid(cap2,indices2,imgOutPath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allPairs = np.vstack([indicesPair,indicesPairRandom])\n",
    "counter = 0\n",
    "for pair in allPairs:\n",
    "    img1 = cv2.imread(imgOutPath1+str(pair[0])+'.png')\n",
    "    img2 = cv2.imread(imgOutPath2+str(pair[1])+'.png')\n",
    "\n",
    "    imgPair = np.hstack([img1,img2])\n",
    "\n",
    "    cv2.imwrite(folderPath+'images/trainData/'+str(counter)+'.jpg',imgPair)\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
